{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "data_filename = 'covtype.csv'\n",
    "df = pd.read_csv(data_filename)\n",
    "\n",
    "#In order to avoid cheating, we split the data into training and testing datasets.\n",
    "train,test = train_test_split(df,test_size=0.2,random_state=999)\n",
    "\n",
    "#create the variable that we will use to train and evaluate our models.\n",
    "train_x = train.loc[:, train.columns != 'Cover_Type']\n",
    "train_y = train['Cover_Type']\n",
    "\n",
    "test_x = test.loc[:, test.columns != 'Cover_Type']\n",
    "test_y = test['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check for missing values. Fortunetely, we do not have any NaNs.\n",
    "df_nas = df.isnull().sum()\n",
    "df_nas = df_nas[df_nas>0]\n",
    "df_nas.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a dataframe that we will store the results of each model\n",
    "Model_Results = pd.DataFrame()\n",
    "Model_Results['Evaluators'] = ['Accuracy Score','Report']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate our models via accuracy score.\n",
    "Accuracy score is the the percentage of correctly_predicted_classes.\n",
    "Accuracy has been discused a lot in the Assignment 3, Question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, classification_report is a very nice function to interpret the results of a classification model.\n",
    "\n",
    "Returns:\n",
    "\n",
    "Precision: Out of the predictions of EACH class we identify how many are correctly predicted. Total_Trees_Predicted_Xi/ Total_Correctly_predicted_Xi\n",
    "\n",
    "Recall : Percentage of the trees identified correctly for each class. Total_Correctly_Predicted_Xi / Total_Class_Xi\n",
    "\n",
    "F1-score is a measure of a test's accuracy. It considers both the precision p and the recall r of the test to compute the score: p is the number of correct positive results divided by the number of all positive results\n",
    "\n",
    "More discussion about those measurements have been done on Assignment_3/Question_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1rst mode: DesicionTreeClassifier\n",
    "\n",
    "Simple Explanation:\n",
    "Very similar technique with DesicionTreeRegression (explained on Question1/Assignment4).\n",
    "However, this time you use as split-point critirion Gini impurity or entropy, measuring the information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-567b82d0d660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "#FIRST MODEL DESICIONTREECLASSIFIER\n",
    "#~2min\n",
    "parameters = [\n",
    "    {'max_depth': list(range(5, 15,2))},\n",
    "    {'min_samples_split': [2,3] }\n",
    "]\n",
    "\n",
    "cv = KFold(n_splits=11, shuffle=True, random_state=13)\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(criterion='gini'), parameters, cv = cv, n_jobs = -1)\n",
    "\n",
    "clf = clf.fit(train_x, train_y)\n",
    "\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier\n",
      "Accuracy score:  0.940\n",
      "More Details:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.94      0.94      0.94     42479\n",
      "    class 1       0.95      0.95      0.95     56554\n",
      "    class 2       0.93      0.93      0.93      7148\n",
      "    class 3       0.84      0.83      0.83       559\n",
      "    class 4       0.84      0.85      0.84      1938\n",
      "    class 5       0.87      0.88      0.87      3392\n",
      "    class 6       0.95      0.94      0.95      4133\n",
      "\n",
      "avg / total       0.94      0.94      0.94    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#copy-paste the parameteres from previous cell's output\n",
    "clf = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "#train\n",
    "clf = clf.fit(train_x, train_y)\n",
    "#predict test_y\n",
    "predict = clf.predict(test_x)\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6' ]\n",
    "score = format(accuracy_score(test_y,predict), '.3f')\n",
    "\n",
    "Model_Results['DecisionTreeClassifier'] = score\n",
    "\n",
    "print('Model: DecisionTreeClassifier')\n",
    "print('Accuracy score: ', score)\n",
    "print('More Details:')\n",
    "print(classification_report(test_y, predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd model: RandomForestClassifier\n",
    "\n",
    "The mechanism of this model has been explained on Question_1/Assignment_4.\n",
    "The only difference between RandomForestRegressor and Classifier is that in this case the model uses the most frequent class, instead of the average predicted value of the n_estimators(trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=700, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#SECOND MODEL: RANDOMFORESTCLASSIFIER\n",
    "#Because of the big size of the dataframe we tried to GridSearch with a partition of the data and then use the best parameteres to train our RF.\n",
    "#However, the results were much better when we ran a RandomForest with the default parameters and use all the data.\n",
    "\n",
    "#SKIP THIS CELL\n",
    "'''\n",
    "sample_indices = np.random.choice(df.index, 100000, replace = False)\n",
    "df_sample = df.iloc[sample_indices, :]\n",
    "\n",
    "train_sample, test_sample = train_test_split(df_sample,test_size=0.5,random_state=999)\n",
    "#create the variable that we will use to train and evaluate our models.\n",
    "trainS_x = train_sample.loc[:, train_sample.columns != 'Cover_Type']\n",
    "trainS_y = train_sample['Cover_Type']\n",
    "\n",
    "testS_x = test_sample.loc[:, test_sample.columns != 'Cover_Type']\n",
    "testS_y = test_sample['Cover_Type']\n",
    "\n",
    "tuned_parameters = {'n_estimators': [50, 100, 500, 700], \n",
    "                    'max_depth': list(range(5,17,2)),                    \n",
    "                    }\n",
    "\n",
    "#try all the compinations of the parameters above with GridSearchCV function\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, \n",
    "           n_jobs=-1, verbose=1)\n",
    "\n",
    "clf.fit(trainS_x, trainS_y)\n",
    "#print the best parameters of the model (our models are evaluated by mean squared error)\n",
    "print(clf.best_estimator_)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "Accuracy score:  0.944\n",
      "More Details:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.94      0.95      0.94     42479\n",
      "    class 1       0.95      0.96      0.95     56554\n",
      "    class 2       0.92      0.95      0.94      7148\n",
      "    class 3       0.91      0.84      0.87       559\n",
      "    class 4       0.92      0.73      0.81      1938\n",
      "    class 5       0.92      0.84      0.88      3392\n",
      "    class 6       0.97      0.92      0.95      4133\n",
      "\n",
      "avg / total       0.94      0.94      0.94    116203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(random_state= 2, n_jobs=-1)\n",
    "\n",
    "RF = RF.fit(train_x, train_y)\n",
    "predict_RF = RF.predict(test_x)\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6' ]\n",
    "score = format(accuracy_score(test_y,predict_RF), '.3f')\n",
    "\n",
    "Model_Results['RandomForestClassifier'] = score\n",
    "\n",
    "print('Model: RandomForestClassifier')\n",
    "print('Accuracy score: ', score)\n",
    "print('More Details:')\n",
    "print(classification_report(test_y, predict_RF, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Support Vector Machines.\n",
    "\n",
    "With this model we achieve greater robustness to invividual observations and better classification of most of the observations.\n",
    "The multiclass support is handled according to a one-vs-one scheme.\n",
    "\n",
    "We select the hyperplane with the maximal margin.\n",
    "Support Vector Machines is a very good algorithm to classify data but it has high computational cost.\n",
    "For the reason described above we have to randomly select only a small prartition of our data to train our model(5k train/test datapoints).\n",
    "\n",
    "The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\n",
    "\n",
    "However, it will take about 5mins to train our model without even do some tuning to the parameteres.\n",
    "\n",
    "Simple Explanation of SVMs\n",
    "We want to separate our observations into two classes.\n",
    "We try to find the best hyperplane.\n",
    "We compute the perpendicular distance from each observation to the candidate hyperplane. The smallest of these distances is called the margin.We select the hyperplane with the maximal margin.\n",
    "To avoid overfit, instead of trying to find the biggest margin, SVM allows some observations to lie on the wrong side of the margin.\n",
    "If we have more than two classes, we can work with the strategy One-versus-One Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIRD MODEL: SUPPORT VECTOR MACHINES\n",
    "#we create new training and testing dataframes with randomly selected rows \n",
    "sample_indices = np.random.choice(df.index, 20000, replace = False)\n",
    "df_sample = df.iloc[sample_indices, :]\n",
    "\n",
    "train_sample, test_sample = train_test_split(df_sample,test_size=0.5,random_state=999)\n",
    "#create the variables that we will use to train and evaluate our models.\n",
    "trainS_x = train_sample.loc[:, train_sample.columns != 'Cover_Type']\n",
    "trainS_y = train_sample['Cover_Type']\n",
    "\n",
    "testS_x = test_sample.loc[:, test_sample.columns != 'Cover_Type']\n",
    "testS_y = test_sample['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SupportVectorMachines\n",
      "Accuracy score:  0.520\n",
      "More Details:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.96      0.05      0.10      3586\n",
      "    class 1       0.51      1.00      0.68      5012\n",
      "    class 2       1.00      0.00      0.01       593\n",
      "    class 3       0.00      0.00      0.00        43\n",
      "    class 4       1.00      0.01      0.01       168\n",
      "    class 5       1.00      0.01      0.01       277\n",
      "    class 6       1.00      0.01      0.01       321\n",
      "\n",
      "avg / total       0.74      0.52      0.38     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#~3min\n",
    "svm_model = SVC(gamma=0.001, C=100., random_state = 0)\n",
    "svm_model = svm_model.fit(trainS_x, trainS_y)\n",
    "predict = svm_model.predict(testS_x)\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6' ]\n",
    "score = format(accuracy_score(testS_y,predict), '.3f')\n",
    "\n",
    "Model_Results['SupportVectorMachines'] = score\n",
    "\n",
    "print('Model: SupportVectorMachines')\n",
    "print('Accuracy score: ', score)\n",
    "print('More Details:')\n",
    "print(classification_report(testS_y, predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "In our case we have really bad accuracy_score with the SVC model.\n",
    "This happens for two reasons.\n",
    "1. We use only a small proportion of our data to train our model and we lose a lot of usefull information.\n",
    "2. This model is really slow to train so we cannot apply tuning techniques to find the best parameters\n",
    "All in all, SVM is not a good practice when you have a big dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the accuracy_scores of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluators</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy Score</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Report</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Evaluators RandomForestClassifier\n",
       "0  Accuracy Score                  0.944\n",
       "1          Report                  0.944"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output from the cell above, RandoForestClassifier has the best score.\n",
    "We also showed more details about each class' accuracy.(precision,recall,f1-score etc)\n",
    "\n",
    "RandomForest Details:\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "    class 0       0.94      0.95      0.94     42479\n",
    "    class 1       0.95      0.96      0.95     56554\n",
    "    class 2       0.92      0.95      0.94      7148\n",
    "    class 3       0.91      0.84      0.87       559\n",
    "    class 4       0.92      0.73      0.81      1938\n",
    "    class 5       0.92      0.84      0.88      3392\n",
    "    class 6       0.97      0.92      0.95      4133\n",
    "\n",
    "avg / total       0.94      0.94      0.94    116203\n",
    "\n",
    "From the table above we can see that the most difficult to predict was class 4 (or Tree number 5 : 'Aspen')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find which pair of cover types was hardest to distinguish we calculated for every pair of classes the misspredicted rows as the other type divided by the total misspredicted rows of these types.\n",
    "\n",
    "We need a percentage and not just a count because the dataframe is imbalanced.\n",
    "\n",
    "More specifically:\n",
    "\n",
    "count(type1_wrongly_predicted_as_type2) + count(type2_wrongly_predicted_as_type1) / total_number_of_misspredicted_type1_and_type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hardest to distinguish pair with RandomForestClassifier is: 1-2 (Spruce/Fir and Lodgepole Pine)\n"
     ]
    }
   ],
   "source": [
    "#create a dataframe with the predicted and actual classes of the RandomForestClassifier(our best model)\n",
    "df_forest=pd.DataFrame({'actual': test_y,\n",
    "                 'predict': predict_RF}) \n",
    "\n",
    "#create a dict to store all the results between pairs\n",
    "pairs_missdistinguished_percent = dict()\n",
    "\n",
    "def percentage_of_missdistinguished_pair(df, type1, type2):\n",
    "    #count the number of class2 predicted as class1\n",
    "    t1_as_t2 = len(df.loc[(df['predict'] == type1) & (df['actual'] == type2), :]) \n",
    "    #count the number of class1 predicted as class2\n",
    "    t2_as_t1 = len(df.loc[(df['predict'] == type2) & (df['actual'] == type1), :])\n",
    "    #total number of both types\n",
    "    total_misspred_t1 = len(df.loc[(df['actual'] == type1) & (df['predict'] != type1)]) \n",
    "    total_misspred_t2 = len(df.loc[(df['actual'] == type2) & (df['predict'] != type2)]) \n",
    "    #calculate the percentage of missdistinguished types between this spesific pair.\n",
    "    percentage_of_failure = (t1_as_t2 + t2_as_t1)/(total_misspred_t1 + total_misspred_t2)\n",
    "    return percentage_of_failure\n",
    "    \n",
    "#ALL THE PAIRS\n",
    "pairs = [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(2,3),(2,4),(2,5),(2,6),(2,7),(3,4),(3,5),(3,6),(3,7),(4,5),(4,6),(4,7),(5,6),(5,7),(6,7)]\n",
    "#run the function for every pair\n",
    "for pair in pairs:\n",
    "    #store the results into the dictionary that we created above\n",
    "    type_pair = str(pair[0]) + '-'+ str(pair[1])\n",
    "    pairs_missdistinguished_percent[type_pair] = percentage_of_missdistinguished_pair(df_forest,pair[0],pair[1])\n",
    "\n",
    "print('The hardest to distinguish pair with RandomForestClassifier is: ' + max(pairs_missdistinguished_percent,key=pairs_missdistinguished_percent.get) + ' (Spruce/Fir and Lodgepole Pine)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature 0 Elevation (0.229259)\n",
      "2. feature 5 Horizontal_Distance_To_Roadways (0.115043)\n",
      "3. feature 9 Horizontal_Distance_To_Fire_Points (0.114200)\n",
      "4. feature 3 Horizontal_Distance_To_Hydrology (0.061379)\n",
      "5. feature 4 Vertical_Distance_To_Hydrology (0.057739)\n",
      "6. feature 1 Aspect (0.047952)\n",
      "7. feature 8 Hillshade_3pm (0.040994)\n",
      "8. feature 7 Hillshade_Noon (0.040496)\n",
      "9. feature 6 Hillshade_9am (0.039773)\n",
      "10. feature 13 Wilderness_Area4 (0.038369)\n",
      "11. feature 2 Slope (0.033225)\n",
      "12. feature 35 Soil_Type22 (0.016159)\n",
      "13. feature 17 Soil_Type4 (0.014934)\n",
      "14. feature 25 Soil_Type12 (0.012245)\n",
      "15. feature 36 Soil_Type23 (0.012050)\n",
      "16. feature 23 Soil_Type10 (0.011607)\n",
      "17. feature 52 Soil_Type39 (0.011203)\n",
      "18. feature 15 Soil_Type2 (0.010222)\n",
      "19. feature 51 Soil_Type38 (0.009885)\n",
      "20. feature 12 Wilderness_Area3 (0.009085)\n",
      "21. feature 10 Wilderness_Area1 (0.008938)\n",
      "22. feature 11 Wilderness_Area2 (0.007310)\n",
      "23. feature 53 Soil_Type40 (0.006869)\n",
      "24. feature 45 Soil_Type32 (0.004983)\n",
      "25. feature 37 Soil_Type24 (0.004600)\n",
      "26. feature 46 Soil_Type33 (0.004569)\n",
      "27. feature 42 Soil_Type29 (0.004427)\n",
      "28. feature 19 Soil_Type6 (0.004138)\n",
      "29. feature 44 Soil_Type31 (0.003823)\n",
      "30. feature 26 Soil_Type13 (0.003523)\n",
      "31. feature 43 Soil_Type30 (0.003145)\n",
      "32. feature 24 Soil_Type11 (0.002744)\n",
      "33. feature 16 Soil_Type3 (0.002644)\n",
      "34. feature 33 Soil_Type20 (0.002003)\n",
      "35. feature 48 Soil_Type35 (0.001791)\n",
      "36. feature 30 Soil_Type17 (0.001732)\n",
      "37. feature 32 Soil_Type19 (0.001200)\n",
      "38. feature 34 Soil_Type21 (0.000879)\n",
      "39. feature 29 Soil_Type16 (0.000818)\n",
      "40. feature 18 Soil_Type5 (0.000754)\n",
      "41. feature 40 Soil_Type27 (0.000523)\n",
      "42. feature 47 Soil_Type34 (0.000496)\n",
      "43. feature 50 Soil_Type37 (0.000415)\n",
      "44. feature 14 Soil_Type1 (0.000411)\n",
      "45. feature 27 Soil_Type14 (0.000405)\n",
      "46. feature 39 Soil_Type26 (0.000287)\n",
      "47. feature 41 Soil_Type28 (0.000196)\n",
      "48. feature 31 Soil_Type18 (0.000157)\n",
      "49. feature 22 Soil_Type9 (0.000142)\n",
      "50. feature 38 Soil_Type25 (0.000113)\n",
      "51. feature 49 Soil_Type36 (0.000093)\n",
      "52. feature 21 Soil_Type8 (0.000030)\n",
      "53. feature 20 Soil_Type7 (0.000018)\n",
      "54. feature 28 Soil_Type15 (0.000006)\n"
     ]
    }
   ],
   "source": [
    "#Here we will order the features according to their importance for the RandomForest model.\n",
    "X = train_x\n",
    "Y = train_y\n",
    "\n",
    "importances = RF.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in RF.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], train_x.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 54)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAJOCAYAAACjqVHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f948a0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.title(\"Feature importances for RandomForestClassifier\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selection:\n",
    "\n",
    "The model with the best score(RandomForestClassifier) is using all the variables to predict the cover type.\n",
    "This is quite normal because even if we have a max depth on this model, RandomForest is selecting for each estimator(DecTree) a number m of random predictors(features) as have been explained(Question1/Assign4).\n",
    "\n",
    "We can prove that on the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier uses all the features:  True\n"
     ]
    }
   ],
   "source": [
    "#model.feature_importances_ get the importance for every feature that have been used even if that value is too small.\n",
    "print('RandomForestClassifier uses all the features: ',len(train_x.columns) == len(RF.feature_importances_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
